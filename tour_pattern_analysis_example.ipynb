{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import re\n",
    "import osmnx as ox\n",
    "import geopandas\n",
    "import json\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from datetime import datetime, date\n",
    "from dateutil import parser\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim, GoogleV3\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(os.path.expanduser(\"\")) \n",
    "df3 = pd.read_excel(xls, 'VehicleSurvey')\n",
    "df4 = pd.read_excel(xls, 'ActivitySurvey')\n",
    "df4['D_1'] = df4['D_1'].fillna(value = '0')\n",
    "#df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''running this cell takes some time'''\n",
    "df6 = pd.read_csv(os.path.expanduser(\"\"),\n",
    "                  names=['timestamp','long','diffseconds','instantspeed','diffdistance','accuracy',\n",
    "                         'lati','device_id'])\n",
    "\n",
    "def TimeParse(x):\n",
    "    a = ''.join([re.split(':|}|{|', x)[4], ':', re.split(':|}|{|', x)[5], \n",
    "            ':', re.split(':|}|{|', x)[6]]).strip('\"')\n",
    "    return parser.parse(a)\n",
    "\n",
    "df6['time'] = df6['timestamp'].apply(lambda x: TimeParse(x))\n",
    "df6['ID'] = df6['device_id'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"'))\n",
    "df6['lon'] = df6['long'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"')).astype(float)\n",
    "df6['lat'] = df6['lati'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"')).astype(float)\n",
    "df6['speed'] = df6['instantspeed'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"')).astype(float)\n",
    "df6['diff_distance'] = df6['diffdistance'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"')).astype(float)\n",
    "df6['diff_time'] = df6['diffseconds'].apply(lambda x: re.split(':|}|{|',x)[3].strip('\"')).astype(float)\n",
    "df6['day'] = df6['time'].apply(lambda x: x.date())\n",
    "\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df8 is all stops of vehicles that have been tasked for household delivery'''\n",
    "\n",
    "df8 = df4.merge(df6, left_on=['Survey ID','DS_4','DS_5'], right_on=['ID','lon','lat'], how='inner')\n",
    "df5 = df4[(df4['D_1'].isin(['2','5'])) & (df4['D_2'] == 8.0)]\n",
    "df8 = df8[df8['Survey ID'].isin(df5['Survey ID'].unique())]\n",
    "#df8 = pd.concat([df8.iloc[:,2:12],df8.iloc[:,16:23],df8.iloc[:,34:36]],axis=1)\n",
    "df8 = df8.drop_duplicates(['DS_3'])\n",
    "df8 = df8.drop_duplicates(['Survey ID','time'])\n",
    "df8 = df8.reset_index(drop=False)\n",
    "df8['date'] = df8['time'].apply(lambda x: x.date())\n",
    "df8['hour'] = df8['time'].apply(lambda x: x.hour)\n",
    "\n",
    "stopkey1_df8 = df8[df8['D_1'] == '1']['DS_3'].unique()\n",
    "array_stop1_df8 = np.array([[re.split('-',key)[0],re.split('-',key)[1]] for key in stopkey1_df8])\n",
    "df_stop1 = pd.DataFrame(data = array_stop1_df8,\n",
    "                        columns = ['ID','pick_up'])\n",
    "code_stop1_df8 = [df8[df8['DS_3'] == key]['D_2'].unique() for key in stopkey1_df8]\n",
    "df_stop1['pick_up_code'] = code_stop1_df8\n",
    "\n",
    "stopkey2_df8 = df8[df8['D_1'] == '2']['DS_3'].unique()\n",
    "array_stop2_df8 = np.array([[re.split('-',key)[0],re.split('-',key)[1]] for key in stopkey2_df8])\n",
    "df_stop2 = pd.DataFrame(data = array_stop2_df8,\n",
    "                        columns = ['ID','deliver'])\n",
    "code_stop2_df8 = [df8[df8['DS_3'] == key]['D_2'].unique() for key in stopkey2_df8]\n",
    "df_stop2['deliver_code'] = code_stop2_df8\n",
    "\n",
    "df_stop_both = df_stop1.merge(df_stop2, on = 'ID', how = 'inner')\n",
    "df_stop_both['pick_up'] = df_stop_both['pick_up'].astype(int)\n",
    "df_stop_both['deliver'] = df_stop_both['deliver'].astype(int)\n",
    "df_stop_both = df_stop_both[df_stop_both['pick_up'] < df_stop_both['deliver']]\n",
    "\n",
    "## condition for filter redundant rows\n",
    "d = {'pick_up':'max'}\n",
    "\n",
    "#'''df13 finds the trip(pick up and deliver stops) for all vehicles'''\n",
    "df13 = df_stop_both.groupby(['ID','deliver']).aggregate(d)\n",
    "df13.index.names = ['level_1', 'level_2']\n",
    "df13['ID'] = df13.index.get_level_values('level_1')\n",
    "df13['deliver'] = df13.index.get_level_values('level_2')\n",
    "\n",
    "#'''df14 finds the number of delivery stops for each vehicle after it's each picking up stop'''\n",
    "df14 = pd.DataFrame(df13.groupby(['ID','pick_up']).size().rename('count'))\n",
    "\n",
    "#'''df15 finds the frequency(distribution) of the number of delivery stops'''\n",
    "#'''473 delivery stops? not all are delivery to household'''\n",
    "df15 = pd.DataFrame(df14.groupby(['count']).size().rename('freq'))\n",
    "df15['share'] = df15['freq'] / df15['freq'].sum()\n",
    "\n",
    "#'''df41 finds all tours with establishments of pick up and deliver'''\n",
    "df41 = df13.merge(df_stop_both, on = ['ID','pick_up','deliver'], how = 'inner')\n",
    "df41 = df41.sort_values(by = ['ID','pick_up','deliver'])\n",
    "df41['pick_up_ID'] = df41['ID'] + '-' + df41['pick_up'].astype(str)\n",
    "df41['deliver_ID'] = df41['ID'] + '-' + df41['deliver'].astype(str)\n",
    "\n",
    "df41['pick_up_code'] = df41['pick_up_code'].astype(str)\n",
    "df41['pick_up_code'] = df41['pick_up_code'].apply(lambda x: x.strip('[]'))\n",
    "df41['deliver_code'] = df41['deliver_code'].astype(str)\n",
    "df41['deliver_code'] = df41['deliver_code'].apply(lambda x: x.strip('[]'))\n",
    "\n",
    "#df_stop_both.head()\n",
    "df41.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df43 records delivery tours(without pick up for now)'''\n",
    "\n",
    "#pd.DataFrame([np.array(df41[df41['pick_up_ID'] == key]['deliver_code'].values, dtype = object) \n",
    "              #for key in df41['pick_up_ID'].unique()])\n",
    "#len(np.array(df41[df41['pick_up_ID'] == df41['pick_up_ID'].unique()[0]]['deliver_code'].values, dtype = object))\n",
    "df43 = pd.DataFrame([df41[df41['pick_up_ID'] == key]['deliver_code'].values for key in df41['pick_up_ID'].unique()])\n",
    "df43 = df43.T\n",
    "df43 = df43.fillna(0)\n",
    "keep_index = [ind for ind in df43.columns if ((df43[ind] == '8.').any())]\n",
    "#df43 = df43.T\n",
    "df43 = df43.iloc[:,keep_index]\n",
    "#df43 = df43.T\n",
    "\n",
    "pd.DataFrame(pd.DataFrame(data = [sum(~df43[ind][:-1].isin(['8.', 0])) for ind in df43.columns],\n",
    "            columns = ['number of non-house stops']).groupby(['number of non-house stops']).size().rename('count'))\n",
    "#df43[0].bfill().ffill().is_unique\n",
    "#[col for col in df.columns if not df[col].is_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''to plot on qgis with tour id'''\n",
    "all_house_index = [ind for ind in df43.columns if ((df43[ind][:-1].isin(['8.',0]).all()))]\n",
    "\n",
    "all_house_stop_record = df8[df8['DS_3'].isin(all_house_stop_ID)]\n",
    "\n",
    "'''all_house_stop_ID find stop_ID(p/d) for all-house tours'''\n",
    "all_house_stop_ID = np.hstack([df41[df41['pick_up_ID'].\n",
    "                                       isin(df41['pick_up_ID'].unique()[all_house_index])]['deliver_ID'].values , \n",
    "                                  df41['pick_up_ID'].unique()[all_house_index]])\n",
    "\n",
    "all_house_pickup_stop_ID = df41['pick_up_ID'].unique()[all_house_index]\n",
    "all_house_delivery_stop_ID = df41[df41['pick_up_ID'].\n",
    "                                       isin(df41['pick_up_ID'].unique()[all_house_index])]['deliver_ID'].values\n",
    "\n",
    "all_house_pickup_stop_record = df8[df8['DS_3'].isin(all_house_pickup_stop_ID)]\n",
    "all_house_pickup_stop_record = all_house_pickup_stop_record.reset_index(drop=True)\n",
    "all_house_pickup_stop_record = all_house_pickup_stop_record.merge(df64, on = 'index', how = 'inner')\n",
    "#all_house_pickup_stop_record.to_csv('all_house_pickup_stop.csv')\n",
    "all_house_delivery_stop_record = df8[df8['DS_3'].isin(all_house_delivery_stop_ID)]\n",
    "all_house_delivery_stop_record = all_house_delivery_stop_record.reset_index(drop=True)\n",
    "all_house_delivery_stop_record = all_house_delivery_stop_record.merge(df64, on = 'index', how = 'inner')\n",
    "#all_house_delivery_stop_record.to_csv('all_house_delivery_stop.csv')\n",
    "all_house_pickup_stop_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(values, indices):\n",
    "    idx = 0\n",
    "    for index in indices:\n",
    "        sublist = []\n",
    "        while idx < len(values) and values[idx] < index:\n",
    "            sublist.append(values[idx])\n",
    "            idx += 1\n",
    "        if sublist:\n",
    "            yield np.hstack([sublist, index])\n",
    "        else:\n",
    "            yield [index]\n",
    "\n",
    "def check_tour(sequence):\n",
    "    #if ('1' or '2') not in sequence: return None\n",
    "    if (('1' not in sequence) and ('2' not in sequence)): return None\n",
    "    if (('1' in sequence) and ('2' not in sequence)): return 1\n",
    "    if (('2' in sequence) and ('1' not in sequence)): return 2\n",
    "    if ('1' and '2') in sequence:\n",
    "        #for s in sequence:\n",
    "        ind1 = [i for i,s in enumerate(sequence) if s == '1']     # index of pickup in the tour sequence\n",
    "        ind2 = [i for i,s in enumerate(sequence) if s == '2']\n",
    "        #tour_ind = list(get_tour(ind1, ind2))\n",
    "        tour_ind = list(partition(ind1, ind2))     # index in separate tours\n",
    "        tour = [[sequence[tour_ind[j][i]] for i in range(len(tour_ind[j]))] \n",
    "                for j in range(len(tour_ind))]     # separate tours\n",
    "        return tour            \n",
    "            \n",
    "def refine_tour(tour):\n",
    "    if tour == None: return None\n",
    "    if tour == 1: return 1\n",
    "    if tour == 2: return 2\n",
    "    else:\n",
    "        for i in range(len(tour)):\n",
    "            if tour[i] == [u'2'] and i>0:\n",
    "                for j in reversed(range(i)):\n",
    "                    if tour[j] != [u'2']:\n",
    "                        tour[j].append(u'2')\n",
    "                        break\n",
    "        \n",
    "        alltour = []\n",
    "        for subtour in tour:\n",
    "            if subtour!= [u'2']:\n",
    "                alltour.append(subtour)\n",
    "        #for i in range(len(tour)):\n",
    "            #if tour[i] == [u'2']:\n",
    "                #tour[i] = [0]\n",
    "        return alltour\n",
    "        \n",
    "def get_tour_type(tour):\n",
    "    if tour:\n",
    "        times_pickup = len([s for s in tour if s == '1'])\n",
    "        times_deliver = len([s for s in tour if s == '2'])\n",
    "        if times_pickup == 1 and times_deliver == 1:\n",
    "            return 'direct tour'\n",
    "        elif times_pickup == 1 and times_deliver > 1:\n",
    "            return 'unloading'\n",
    "        elif times_pickup > 1 and times_deliver == 1:\n",
    "            return 'loading'\n",
    "        elif times_pickup > 1 and times_deliver > 1:\n",
    "            return 'mixed'\n",
    "        else:\n",
    "            return 'NA'\n",
    "        \n",
    "def get_num_deliver_stop(tour):\n",
    "    if tour:\n",
    "        return len([s for s in tour if s == '2'])\n",
    "    \n",
    "def get_num_pickup_stop(tour):\n",
    "    if tour:\n",
    "        return len([s for s in tour if s == '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tour_index(df):\n",
    "    if df[5] not in [1,2,None]:\n",
    "        tour_length = [len(s) for s in df[5]]\n",
    "        sublist = []\n",
    "        for i in range(len(tour_length)):\n",
    "            front_ind = sum(tour_length[:i+1]) - tour_length[0]\n",
    "            end_ind = sum(tour_length[:i+1])\n",
    "            sublist.append(df[4][front_ind:end_ind])\n",
    "            \n",
    "        return sublist\n",
    "    \n",
    "def get_tot_dist(df):\n",
    "    #return sum([df8[df8['index'] == ind]['diff_distance'].values for ind in x if ind in list(df8['index'])])[0] \n",
    "    x = df['tour_index_number']\n",
    "    y = df['ID']\n",
    "    if x == None: return None\n",
    "    else:\n",
    "        if len(x) == 1:\n",
    "            f,l = x[0][0], x[0][-1]\n",
    "            first = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[0]['time']].index.values[0]\n",
    "            last = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[-1]['time']].index.values[0]\n",
    "            return sum(df6[(df6['ID'] == y) & (df6.index.isin(range(first,last+1)))]['diff_distance'])/1000.\n",
    "        elif len(x) > 1:\n",
    "            record = []\n",
    "            for i in range(len(x)):\n",
    "                f,l = x[i][0], x[i][-1]\n",
    "                first = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[0]['time']].index.values[0]\n",
    "                last = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[-1]['time']].index.values[0]\n",
    "                record.append(sum(df6[(df6['ID'] == y) & (df6.index.isin(range(first,last+1)))]['diff_distance'])/1000.)\n",
    "            return record\n",
    "        else: return None\n",
    "\n",
    "def get_tot_time(df):\n",
    "    #return sum([df8[df8['index'] == ind]['diff_distance'].values for ind in x if ind in list(df8['index'])])[0] \n",
    "    x = df['tour_index_number']\n",
    "    y = df['ID']\n",
    "    if x == None: return None\n",
    "    else:\n",
    "        if len(x) == 1:\n",
    "            f,l = x[0][0], x[0][-1]\n",
    "            first = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[0]['time']].index.values[0]\n",
    "            last = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[-1]['time']].index.values[0]\n",
    "            return sum(df6[(df6['ID'] == y) & (df6.index.isin(range(first,last+1)))]['diff_time'])/60.\n",
    "        elif len(x) > 1:\n",
    "            record = []\n",
    "            for i in range(len(x)):\n",
    "                f,l = x[i][0], x[i][-1]\n",
    "                first = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[0]['time']].index.values[0]\n",
    "                last = df6[df6['time'] == df8[df8['index'].isin(range(f,l+1))].iloc[-1]['time']].index.values[0]\n",
    "                record.append(sum(df6[(df6['ID'] == y) & (df6.index.isin(range(first,last+1)))]['diff_time'])/60.)\n",
    "            return record\n",
    "        else: return None\n",
    "        \n",
    "def get_tour_dist(df):\n",
    "    record = []\n",
    "    for i in range(len(df)):\n",
    "        item = df.iloc[i]['total_distance']\n",
    "        if item != None:\n",
    "            if type(item) == list:\n",
    "                for em in item:\n",
    "                    record.append(em)\n",
    "            elif type(item) == float:\n",
    "                record.append(item)\n",
    "                \n",
    "    return record\n",
    "\n",
    "def get_tour_time(df):\n",
    "    record = []\n",
    "    for i in range(len(df)):\n",
    "        item = df.iloc[i]['total_time']\n",
    "        if item != None:\n",
    "            if type(item) == list:\n",
    "                for em in item:\n",
    "                    record.append(em)\n",
    "            elif type(item) == float:\n",
    "                record.append(item)\n",
    "                \n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tour_process(df):\n",
    "    df58 = pd.DataFrame(df.groupby(['date','Survey ID'])['D_1'].apply(list).rename('stop_sequence'))  # cool stuff\n",
    "    df59 = pd.DataFrame(df.groupby(['date','Survey ID'])['time'].apply(list).rename('time'))\n",
    "    df60 = pd.DataFrame(df.groupby(['date','Survey ID'])['D_2'].apply(list).rename('establishment'))\n",
    "    df61 = pd.DataFrame(df.groupby(['date','Survey ID'])['D_4'].apply(list).rename('type_product'))\n",
    "    df62 = pd.DataFrame(df.groupby(['date','Survey ID']).index.apply(list).rename('index_number'))\n",
    "    df58 = pd.concat([df58,df59,df60,df61,df62], axis = 1)\n",
    "    df58['tour'] = df58['stop_sequence'].apply(lambda x: check_tour(x))\n",
    "    df58['tour'] = df58['tour'].apply(lambda x: refine_tour(x))\n",
    "    alltour = []\n",
    "    for tour in df58[~df58['tour'].isin([None,1,2])]['tour']:\n",
    "        for subtour in tour:\n",
    "            if subtour != [0]:\n",
    "                alltour.append(subtour)\n",
    "                \n",
    "    values, counts = np.unique(alltour, return_counts=True)\n",
    "    df59 = pd.DataFrame(data = values, columns = ['tour'])\n",
    "    df59['counts'] = counts\n",
    "    \n",
    "    alltour_type = [get_tour_type(tour) for tour in alltour]\n",
    "    val, coun = np.unique(alltour_type, return_counts=True)\n",
    "    df60 = pd.DataFrame(data = val, columns = ['tour_type'])\n",
    "    df60['counts'] = coun\n",
    "    \n",
    "    return df58, df59, df60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(chain.from_iterable(dict_stop1))\n",
    "'''def get_tour_index(df):\n",
    "    if df[5] != 2:\n",
    "        tour_length = [len(s) for s in df[5]]\n",
    "        sublist = []\n",
    "        for i in range(len(tour_length)):\n",
    "            front_ind = sum(tour_length[:i+1]) - tour_length[0]\n",
    "            end_ind = sum(tour_length[:i+1])\n",
    "            sublist.append(df[4][front_ind:end_ind])\n",
    "            \n",
    "        return sublist'''\n",
    "\n",
    "df63 = get_tour_process(all_house_stop_record)[0]\n",
    "df63['tour_index_number'] = df63.apply(get_tour_index, axis = 1)    # cool stuff\n",
    "#df63['total_distance'] = df63['tour_index_number'].apply(lambda x: get_tot_dist(x))\n",
    "df63['ID'] = np.zeros(len(df63))\n",
    "for i in range(len(df63)):\n",
    "    df63['ID'].iloc[i] = df63.index[i][1]\n",
    "df63['total_distance'] = df63.apply(get_tot_dist, axis = 1)\n",
    "df63['total_time'] = df63.apply(get_tot_time, axis = 1)\n",
    "#df63['is_overnight'] = df63.apply(identify_overnight_tour, axis = 1)\n",
    "#df63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df8 is all stops of vehicles that have been tasked for household delivery'''\n",
    "\n",
    "def get_tour_step1(estab,df4,df6):\n",
    "    df_estab = df4[(df4['D_1'].isin(['2','5'])) & (df4['D_2'] == estab)]\n",
    "    #df_estab = pd.concat([df_estab.iloc[:,2:12],df_estab.iloc[:,16:23]],axis=1)\n",
    "    df = df4.merge(df6, left_on=['Survey ID','DS_4','DS_5'], right_on=['ID','lon','lat'], how='inner')\n",
    "    df = df[df['Survey ID'].isin(df_estab['Survey ID'].unique())]\n",
    "    df = pd.concat([df.iloc[:,2:12],df.iloc[:,16:23],df.iloc[:,34:36]],axis=1)\n",
    "    df = df.drop_duplicates(['DS_3'])\n",
    "    df = df.drop_duplicates(['Survey ID','time'])\n",
    "    df = df.reset_index(drop=False)\n",
    "    \n",
    "    stopkey1 = df[df['D_1'] == '1']['DS_3'].unique()\n",
    "    array_stop1 = np.array([[re.split('-',key)[0],re.split('-',key)[1]] for key in stopkey1])\n",
    "    df_stop1 = pd.DataFrame(data = array_stop1,\n",
    "                        columns = ['ID','pick_up'])\n",
    "    df_stop1['pick_up'] = pd.to_numeric(df_stop1['pick_up'], errors='coerce')  # deal with NAN values\n",
    "    df_stop1['pick_up'] = df_stop1['pick_up'].fillna(0)\n",
    "    code_stop1 = [df[df['DS_3'] == key]['D_2'].unique() for key in stopkey1]\n",
    "    df_stop1['pick_up_code'] = code_stop1\n",
    "    \n",
    "    stopkey2 = df[df['D_1'] == '2']['DS_3'].unique()\n",
    "    array_stop2 = np.array([[re.split('-',key)[0],re.split('-',key)[1]] for key in stopkey2])\n",
    "    df_stop2 = pd.DataFrame(data = array_stop2,\n",
    "                        columns = ['ID','deliver'])\n",
    "    df_stop2['deliver'] = pd.to_numeric(df_stop2['deliver'], errors='coerce')  # deal with NAN values\n",
    "    df_stop2['deliver'] = df_stop2['deliver'].fillna(0)\n",
    "    code_stop2 = [df[df['DS_3'] == key]['D_2'].unique() for key in stopkey2]\n",
    "    df_stop2['deliver_code'] = code_stop2\n",
    "    \n",
    "    df_stop_both = df_stop1.merge(df_stop2, on = 'ID', how = 'inner')\n",
    "    df_stop_both['pick_up'] = df_stop_both['pick_up'].astype(int)\n",
    "    #df_stop_both['deliver'] = pd.to_numeric(df_stop_both['deliver'], errors='coerce')  # deal with NAN values\n",
    "    #df_stop_both['deliver'] = df_stop_both['deliver'].fillna(0)\n",
    "    df_stop_both['deliver'] = df_stop_both['deliver'].astype(int)\n",
    "    df_stop_both = df_stop_both[df_stop_both['pick_up'] < df_stop_both['deliver']]\n",
    "\n",
    "    ## condition for filter redundant rows\n",
    "    d = {'pick_up':'max'}\n",
    "\n",
    "    '''finds the trip(pick up and deliver stops) for all vehicles'''\n",
    "    df_1 = df_stop_both.groupby(['ID','deliver']).aggregate(d)\n",
    "\n",
    "    '''finds the number of delivery stops for each vehicle after it's each picking up stop'''\n",
    "    df_2 = pd.DataFrame(df_1.groupby(['ID','pick_up']).size().rename('count'))\n",
    "    \n",
    "    df_3 = pd.DataFrame(df14.groupby(['count']).size().rename('freq'))\n",
    "    df_3['share'] = df_3['freq'] / df_3['freq'].sum()\n",
    "    \n",
    "    df = df_1.merge(df_stop_both, on = ['ID','pick_up','deliver'], how = 'inner')\n",
    "    df = df.sort_values(by = ['ID','pick_up','deliver'])\n",
    "    df['pick_up_ID'] = df['ID'] + '-' + df['pick_up'].astype(str)\n",
    "    df['pick_up_code'] = df['pick_up_code'].astype(str)\n",
    "    df['pick_up_code'] = df['pick_up_code'].apply(lambda x: x.strip('[]'))\n",
    "    df['deliver_code'] = df['deliver_code'].astype(str)\n",
    "    df['deliver_code'] = df['deliver_code'].apply(lambda x: x.strip('[]'))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = df15.index, height = df15['share'], width = 0.45, color = 'r', align = 'center', \n",
    "        label = 'household delivery vehicle')\n",
    "plt.bar(x = df18.index + 0.45, height = df18['share'], width = 0.45, color = 'b', align = 'center', \n",
    "        label = 'all vehicles')\n",
    "plt.xlabel('number of delivery stops')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend()\n",
    "plt.title('distribution of number of delivery stops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''distribution of delivery origins (pickup locations)'''\n",
    "\n",
    "ind_D2 = ['company office/headquarters', 'WH/DC',\n",
    "          'transfer terminal/ports', 'manufacturer/factory',\n",
    "          'construction site', 'farm',\n",
    "          'retail/food establishment', 'private residence',\n",
    "          'other']\n",
    "\n",
    "df22 = pd.DataFrame(df20.groupby('D_2').size().rename('freq'))\n",
    "\n",
    "ind_D2_house = ['company office/headquarters', 'WH/DC',\n",
    "          'manufacturer/factory',\n",
    "        'farm',\n",
    "          'retail/food establishment', 'private residence',\n",
    "          'other']\n",
    "\n",
    "df21 = pd.DataFrame(df19.groupby('D_2').size().rename('freq'))\n",
    "\n",
    "\n",
    "plt.subplots(3,1, figsize = (12,10))\n",
    "'''same horizontal axis?'''\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.barh(y = ind_D2_house, width = df21.freq)\n",
    "plt.title('distribution of pickup locations for vehicles deliver to household')\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.barh(y = ind_D2, width = df22.freq)\n",
    "plt.title('distribution of pickup locations for all vehicles')\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.barh(y = ind_D2, width = df22.freq, label = 'all vehicles')\n",
    "plt.barh(y = ind_D2_house, width = df21.freq, label = 'vehicles to household')\n",
    "ind22 = np.arange(len(df22))\n",
    "ind21 = np.arange(len(df21))\n",
    "height = 0.4\n",
    "#plt.barh(y = ind_D2, width = df22.freq, height = height, label = 'all')\n",
    "#plt.barh(y = ind_D2_house + height, width = df21.freq, height = height, label = 'household')\n",
    "plt.legend()\n",
    "plt.title('distribution of pickup locations')\n",
    "plt.savefig('pickup_origin.png')\n",
    "#plt.xticks(rotation='vertical')\n",
    "#plt.xticks(rotation=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''analyze repetitiveness bahavior?'''\n",
    "'''more complete list of malls (over 200 malls)'''\n",
    "malls = pd.read_csv(os.path.expanduser(\"~/Documents/malls.csv\"))\n",
    "def process_malls(mall_location,distance):\n",
    "    mall_location['possible_match'] = range(len(mall_location))\n",
    "    for i in range(len(mall_location)):\n",
    "        lon1, lat1 = mall_location['lon'].iloc[i], mall_location['lat'].iloc[i]\n",
    "        df_distance_try = pd.DataFrame(data = [haversine(lon1, lat1, df_retail['DS_4'].iloc[ind], df_retail['DS_5'].iloc[ind]) \n",
    "                                               for ind in range(len(df_retail))],\n",
    "                                       columns = ['distance'])\n",
    "        mall_location['possible_match'].iloc[i] = np.array(df_distance_try[df_distance_try['distance'] < distance].index.values,\n",
    "                                                           dtype = object)\n",
    "    \n",
    "    mall_location['possible_match_len'] = mall_location['possible_match'].apply(lambda x: len(x))\n",
    "    return mall_location\n",
    "    \n",
    "df65 = process_malls(malls,0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''look into location of malls'''\n",
    "'''running this cell takes a while'''\n",
    "'''mall is at 313 Orchard Road, find 176, 181, 290, 391 all working, \n",
    "or some other close location, is this correct?'''\n",
    "\n",
    "mall_location = pd.read_excel(os.path.expanduser(\"~/Documents/List of malls in SG.xlsx\"))\n",
    "mall_location['area'] = mall_location.index\n",
    "mall_location = mall_location.reset_index(drop=True)\n",
    "\n",
    "mall_lonlat = [[mall_location['Latitude'].iloc[i], mall_location['Longitude'].iloc[i]] \n",
    "               for i in mall_location.index]\n",
    "\n",
    "#mall_lonlat = [[format(mall_location['Longitude'].iloc[i], '.5f'), format(mall_location['Latitude'].iloc[i],'.5f')] \n",
    "               #for i in mall_location.index]\n",
    "mall_location['latlon'] = mall_lonlat\n",
    "mall_location['latlon'] = mall_location['latlon'].astype(str)\n",
    "mall_location['latlon'] = mall_location['latlon'].apply(lambda x: x.strip('[]'))\n",
    "\n",
    "mall_location['lon'] = mall_location['Longitude'].apply(lambda x: round(x,5))\n",
    "mall_location['lat'] = mall_location['Latitude'].apply(lambda x: round(x,5))\n",
    "\n",
    "df_retail = df9[(df9['D_1'].isin(['2','5'])) & (df9['D_2'] == 7.0) ]\n",
    "df_retail = df_retail.drop_duplicates(['DS_3'])\n",
    "df_retail = df_retail.drop_duplicates(['Survey ID','time'])\n",
    "df_retail = df_retail.reset_index(drop=False)\n",
    "\n",
    "mall_location['possible_match'] = range(len(mall_location))\n",
    "for i in range(len(mall_location)):\n",
    "    lon1, lat1 = mall_location['Longitude'].iloc[i], mall_location['Latitude'].iloc[i]\n",
    "    df_distance_try = pd.DataFrame(data = [haversine(lon1, lat1, df_retail['DS_4'].iloc[ind], df_retail['DS_5'].iloc[ind]) \n",
    "                                           for ind in range(len(df_retail))],\n",
    "                                   columns = ['distance'])\n",
    "    mall_location['possible_match'].iloc[i] = np.array(df_distance_try[df_distance_try['distance'] < 0.5].index.values,\n",
    "                                                   dtype = object)\n",
    "    \n",
    "mall_location['possible_match_len'] = mall_location['possible_match'].apply(lambda x: len(x))\n",
    "\n",
    "'''possible service timeout issue'''    \n",
    "'''def get_location(x):\n",
    "    geolocator = Nominatim()\n",
    "    #geolocator = GoogleV3()\n",
    "    #location = geolocator.geocode(x)\n",
    "    location = geolocator.reverse(x)\n",
    "    return location.address\n",
    "\n",
    "mall_location['location'] = mall_location['lonlat'].apply(lambda x : get_location(x))'''\n",
    "\n",
    "mall_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    geolocator = Nominatim()\n",
    "    #geolocator = GoogleV3()\n",
    "    #location = geolocator.geocode(x)\n",
    "    location = geolocator.reverse(x)\n",
    "    return location.address\n",
    "\n",
    "mall_location['location'] = mall_location['lonlat'].apply(lambda x : get_location(x))\n",
    "\n",
    "mall_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_retail[103:120]\n",
    "#mall_location\n",
    "'''0,7,11,13,25,36,59,73,90,95'''\n",
    "typical_malls = ['313@Somerset','City Square Mall',\n",
    "                 'ION Orchard','Marina Bay Sands',\n",
    "                 'Suntec City','Tampines Mall',\n",
    "                 'Junction 8', 'Hougang Mall',\n",
    "                 'Vivocity','JEM']\n",
    "\n",
    "'''find all index that is possibly deliver to malls'''\n",
    "list(set(np.hstack(mall_location['possible_match'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_D7_mall = ['25x25x25cm', '100x100x100cm', '200x100x100cm', 'one pallet',\n",
    "               'multiple pallet','1/4 truck', '1/2 truck', 'full truck']\n",
    "\n",
    "df46 = pd.DataFrame(df_retail[df_retail.index.isin(list(set(np.hstack(mall_location['possible_match']))))].\n",
    "             groupby(['D_7']).size().rename('counts'))\n",
    "plt.barh(y = ind_D7_mall, width = df46.counts)\n",
    "for i, v in enumerate(df46.counts):\n",
    "    plt.text(v, i, \" \"+str(v), color='black', va='center', fontweight='bold')\n",
    "plt.title('distribution of cargo volumn for vehicles that possibly deliver to mall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for a deliver trip(between 2 stops at picking up points), \n",
    "   most have 0 or 1 deliver stop at private residence location '''\n",
    "\n",
    "\n",
    "df8 = df8.reset_index(drop=True)\n",
    "ind = df8[df8['D_1'] == '1'].index\n",
    "housestop = df8[df8['D_1'] == '2'].index\n",
    "x = np.diff(np.searchsorted(housestop,ind))\n",
    "y = np.bincount(x)\n",
    "ii = np.nonzero(y)[0]\n",
    "zip(ii,y[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''study type of product'''\n",
    "\n",
    "product_type = ['1','2','3','4','5','6','7','8','9','10']\n",
    "product_name = ['live animals','perishable food products',\n",
    "                     'non-perishable food products','bonded goods(alcohol, tobacco)',\n",
    "                     'mineral products','chemicals',\n",
    "                     'sundry items','pharmaceuticals',\n",
    "                     'rubber and leather','wood,paper']\n",
    "\n",
    "'''find counts of product'''\n",
    "def find_product(df, category):\n",
    "    product = df[df.index.isin([df.index[ind] for ind in range(len(df.index))\n",
    "                                if (category in df.index[ind])])]['freq'].sum()\n",
    "    return product\n",
    "\n",
    "'''convert list into df'''\n",
    "def get_df_product(df):\n",
    "    df_product = pd.DataFrame()\n",
    "    df_product['product_type'] = product_type\n",
    "    df_product['product_name'] = product_name\n",
    "    df_product['count'] = [find_product(df, product) for product in product_type]\n",
    "    df_product['count'].iloc[0] = df_product['count'].iloc[0] - df_product['count'].iloc[9]  # modify due to text identification\n",
    "    return df_product\n",
    "\n",
    "def plot_product(df, word):\n",
    "    df_product = get_df_product(df)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.barh(y = np.arange(len(df_product)), width = df_product['count'])\n",
    "    ax.set(yticks = np.arange(len(df_product)), yticklabels = df_product.product_name)\n",
    "    plt.xlabel('number of times delivered')\n",
    "    plt.title('type of products delivered by %s' %(word))\n",
    "    #plt.title('type of products delivered by '{}'.format(word)')\n",
    "    \n",
    "\n",
    "#df27 = pd.DataFrame(van.groupby('D_4').size().rename('freq'))\n",
    "#df_product_van = get_df_product(df27)\n",
    "#df_product_van\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''should be resolved now (wierd result)'''\n",
    "'''dangerous to use df345?'''\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "\n",
    "df27 = pd.DataFrame(van.groupby('D_4').size().rename('freq'))\n",
    "df28 = pd.DataFrame(truck.groupby('D_4').size().rename('freq'))\n",
    "df37 = df345[df345['D_1'].isin(['2','5'])]\n",
    "df38 = pd.DataFrame(df37.groupby('D_4').size().rename('freq'))\n",
    "df35 = df37[df37['D_2'] == '8.0']\n",
    "df29 = pd.DataFrame(df35.groupby('D_4').size().rename('freq'))\n",
    "\n",
    "df31 = get_df_product(df27)  # van\n",
    "df32 = get_df_product(df28)  # truck\n",
    "df33 = get_df_product(df29)  # household\n",
    "\n",
    "'''df39/df38 is all vehicles that have identified stops '''\n",
    "df39 = get_df_product(df38)  # all\n",
    "\n",
    "ind39 = np.arange(len(df39))\n",
    "ind31 = np.arange(len(df31))\n",
    "ind32 = np.arange(len(df32))\n",
    "height = 0.4\n",
    "plt.barh(y = ind39, width = df39['count'], height = 0.55 * height, label = 'all')\n",
    "plt.barh(y = ind31 + 0.5 * height, width = df31['count'], height = 0.55 * height, label = 'van')\n",
    "plt.barh(y = ind32 + height, width = df32['count'], height = 0.55 * height, label = 'truck')\n",
    "ax.set(yticks=ind31 + 0.5 * height, yticklabels=df31.product_name)\n",
    "plt.legend()\n",
    "plt.title('type of products delivered for different vehicle type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_order = pd.DataFrame(columns = ['id','check'])\n",
    "for i,user in enumerate(df66.ID.unique()):\n",
    "    l = df66[df66.ID == user].DS_2\n",
    "    if len(l) > 1:\n",
    "        check = all(l[i] <= l[i+1] for i in xrange(len(l)-1))\n",
    "        check_order.loc[i] = [user, check]\n",
    "    elif len(l) == 1: check_order.loc[i] = [user, False]\n",
    "    else: check_order.loc[i] = [user, False]\n",
    "    #check_order.append()\n",
    "check_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = df6[df6.ID == 'XE3629G'].as_matrix(columns=['lat', 'lon'])\n",
    "#db = DBSCAN(eps=eps, min_samples=ms, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))\n",
    "kms_per_radian = 6371.0088\n",
    "epsilon = 0.05 / kms_per_radian\n",
    "db = DBSCAN(eps=epsilon, min_samples=10, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "clusters = pd.Series([coords[cluster_labels == n] for n in range(num_clusters)])\n",
    "\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "unique_labels = set(cluster_labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (cluster_labels == k)\n",
    "    X = np.radians(coords)\n",
    "    #X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df66[['diff_distance','time']].groupby(pd.Grouper(key='time', freq=\"M\")).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{row[0]:row[-1] for ind,row in df64.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json, requests\n",
    "#url = 'https://api.foursquare.com/v2/venues/VENUE_ID/listed'\n",
    "url = 'https://api.foursquare.com/v2/venues/search'\n",
    "\n",
    "params = dict(\n",
    "  client_id='',\n",
    "  client_secret='',\n",
    "  v='20190814',\n",
    "  #ll='1.3413,103.9638',\n",
    "  #ll='1.3514986,103.9401629',  \n",
    "  ll='1.282302, 103.858528',  \n",
    "  radius=2000,  \n",
    "  #VENUE_ID='HZXXY3Y',  \n",
    "  limit=2000\n",
    "  #query='coffee',\n",
    "  #limit=1\n",
    ")\n",
    "resp = requests.get(url=url, params=params)\n",
    "data1 = json.loads(resp.text)\n",
    "\n",
    "len(data1['response']['venues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = []\n",
    "name = []\n",
    "lat = []\n",
    "lng = []\n",
    "postcode = []\n",
    "address = []\n",
    "category = []\n",
    "for query in data1['response']['venues']:\n",
    "    list_id.append(query['id'])\n",
    "    name.append(query['name'])\n",
    "    lat.append(query['location']['lat'])\n",
    "    lng.append(query['location']['lng'])\n",
    "    #postcode.append(query['venue']['location']['postalCode'])\n",
    "    #postcode.append(query['venue']['location']['formattedAddress'][1])\n",
    "    #if query['location']['postalCode']:\n",
    "        #postcode.append(query['location']['postalCode'])\n",
    "    #else: postcode.append('')\n",
    "    address.append(query['location']['formattedAddress'])\n",
    "    if query['categories']: \n",
    "        category.append(query['categories'][0]['name'])\n",
    "    else: category.append('')\n",
    "    #category.append(query['categories'][0]['name'] if (len(query['categories'] > 0) else: ''))\n",
    "\n",
    "poi_data1 = pd.DataFrame({'id': list_id, \n",
    "                         'name': name,\n",
    "                         'lat': lat,\n",
    "                         'lng': lng,\n",
    "                         #'postcode': postcode,\n",
    "                         'address': address,\n",
    "                         'category': category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
